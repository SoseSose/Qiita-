---
title: phi-2_x_ARC
tags:
  - ''
private: false
updated_at: ''
id: null
organization_url_name: null
slide: false
ignorePublish: false
---

## 目的  

何も学習させていないPhi-2でARCを学習させるとどれくらいの正解率になるのか？
また、どのような種類の問題が解けるのかを大まかに示す。

## Phi-2以外のモデルの正解率

下記のサイトで計測されている。やはりGPT-4は性能が高く
21%の正解率となっている。ただし、オープンではないモデルなので
データリークがある可能性は否定できない。

<https://github.com/alxndrTL/ARC_LLMs>

## 計測したコードに付いて

自作リポジトリの~~~.pyで推論を実行し、~~.pyで正解率と正解したタスクの
視覚化を実装した。

<>

## プロンプトとPhi-2の回答の癖

Phi-2に対して次のような形で入力をすると
ARCの答えを生成するC++のコードを返答される。
これ以外にも文章のようなものを入力とすると
コードで回答されることが多かった。おそらくPhi-2のトレーニングにも
コードが多く、特にこのような数字の羅列とプログラム以外にはなかなか
ないので、このような回答をしたのかと。
ただ、このような形式で受け取ってしまうと処理が難しい(C++の処理系を組み込まないと)ので
数字と記号とインデックスだけを使用して、次のようなプロンプトにした。

結果、まずARCの答えを返答し、その後にその答えを生成するプログラムコードを記載するという
形式を取ってくれるように。

この回答で２行以上改行されているところまでをPhi-2の回答とし、その回答と
本当の答えが同一かを判定することで今回の正答率を計測した。

AIの面倒を見るのも中々、大変で。

## 正解率と正解したタスク

結果は正解率21%だった。

また、正解したタスクは下の画像の通り。  
